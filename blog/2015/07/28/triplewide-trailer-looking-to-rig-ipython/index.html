
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Triplewide Trailer, Part 1 - { lab41 }</title>
  <meta name="author" content="Lab41">

  
  <meta name="description" content="Our last post provided a technical overview of how you can deploy an IPython-driven Spark cluster using Docker containers for each component. That &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://lab41.github.io/blog/2015/07/28/triplewide-trailer-looking-to-rig-ipython/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="{ lab41 }" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="https://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="/stylesheets/custom/bootstrap.min.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="/stylesheets/custom/bootstrap-responsive.min.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="/stylesheets/custom/jquery.fancybox.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="/stylesheets/custom/jquery.fancybox-extra.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="/stylesheets/custom/jquery.fancybox-buttons.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="/stylesheets/custom/jquery.fancybox-thumbs.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="/stylesheets/tables.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="/stylesheets/custom/kronecker.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="https://code.jquery.com/ui/1.10.3/themes/smoothness/jquery-ui.min.css" rel="stylesheet" type="text/css"/>

<script src="/javascripts/jquery-1.9.0.min.js" type="text/javascript"></script>

<script src="/javascripts/fancybox/jquery.fancybox.js" type="text/javascript"></script>
<script src="/javascripts/fancybox/jquery.fancybox-activate.js" type="text/javascript"></script>
<script src="/javascripts/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>
<script src="/javascripts/fancybox/jquery.fancybox-buttons.js" type="text/javascript"></script>
<script src="/javascripts/fancybox/jquery.fancybox-media.js" type="text/javascript"></script>
<script src="/javascripts/fancybox/jquery.fancybox-thumbs.js" type="text/javascript"></script>
<script src="/javascripts/jquery.mousewheel-3.0.6.pack.js" type="text/javascript"></script>
<script src="/javascripts/r_syntax.js" type="text/javascript"></script>
<script src="/javascripts/google_analytics.js" type="text/javascript"></script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/d3/2.10.0/d3.v2.min.js"></script>
<script src="https://code.jquery.com/ui/1.10.3/jquery-ui.min.js"></script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script>
<script src="/javascripts/mathjax.js" type="text/x-mathjax-config"></script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<script type="text/javascript" src="/javascripts/kroneckerapp.js"></script>

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-40906884-1, UA-40464073-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/"><img src="/images/lab41/logo.png" width="212" height="50" alt='Logo' %}> { blog }</a></h1>
  
    <h2>innovation through collaboration</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:lab41.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h3 class="entry-title">Triplewide Trailer, Part 1</h3>
    
    <h5 class="subtitle">Looking to Hitch IPython, Spark, and Mesos to Docker</h5>
    
    
      <p class="meta">
        








  


<time datetime="2015-07-28T12:00:00+00:00" pubdate data-updated="true">Jul 28<span>th</span>, 2015</time>
        
  

<span class="byline author vcard"> - <span class="fn">Kyle Foster</span></span>

        
        
      </p>
    
  </header>


<div class="entry-content"><p>Our <a href="http://lab41.github.io/blog/2015/04/13/ipython-on-spark-on-docker">last post</a> provided a technical overview of how you can deploy an IPython-driven Spark cluster using Docker containers for each component. That setup works well to deploy Spark in standalone mode, but what if you want to run other big data frameworks on the same cluster? With infrastructure tools like <a href="http://mesos.apache.org">Apache Mesos</a>, you can gain fine-grained resource utilization and collapse multiple frameworks – such as Hadoop, Spark, and ElasticSearch – into one cluster. To that end, we’ve been examining how a <a href="https://github.com/Lab41/ipython-spark-docker">Dockerized Spark</a> setup could <a href="https://spark.apache.org/docs/latest/running-on-mesos.html">use Mesos as its task scheduler</a>. What follows is our current thinking on three possible ways that IPython, Spark, Docker, and Mesos can be made to work together.</p>
<div class="margin-bottom-medium">
<img src="/images/post_12_mesos/mesos_resource_sharing.jpg" title="Mesos Resource Sharing" >
</div>
<p>
<small><em>Figure 1: Mesos resource sharing increases throughput and utilization, via <a href="http://www.slideshare.net/caniszczyk/apache-mesos-at-twitter-texas-linuxfest-2014">Apache Mesos at Twitter</a></em></small>
</p>


<h3 id="threes-company">Three’s Company</h3>
<p>Before diving into ways to combine Spark and Mesos with Docker, it will help to give a little background on how Spark <em>typically</em> integrates with Mesos. The interplay between the two systems is important, so bear with me for this quick overview.</p>
<p>Out of the box, it is relatively straightforward for Mesos to distribute Spark tasks to slave nodes. Following the guidance of several <a href="http://www.slideshare.net/pacoid/getting-started-running-apache-spark-on-apache-mesos-30441181">overviews</a> and <a href="http://open.mesosphere.com/tutorials/run-spark-on-mesos">tutorials</a>, the integration begins by first building the Spark binary. Next, you place that binary in an HDFS location each Mesos slave can reach (or alternatively, within the same local directory on each slave). From that point on, when Mesos slaves accept Spark jobs, they retrieve the binary from HDFS (or point to their local path install) to do Spark magic. The following configuration snippet illustrates how to configure Mesos to pull the Spark binary from HDFS:</p>
<div class="bogus-wrapper">
<notextile>
<figure class='code'><figcaption>
<span></span>
</figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'><span class="nb">export </span><span class="nv">MESOS_NATIVE_LIBRARY</span><span class="o">=</span>/usr/local/lib/libmesos.so
</span><span class='line'><span class="nb">export </span><span class="nv">SPARK_EXECUTOR_URI</span><span class="o">=</span>hdfs://hadoop-namenode/tmp/spark-0.8.0-2.0.0-mr1-cdh4.4.0.tgz
</span><span class='line'><span class="nb">export </span><span class="nv">MASTER</span><span class="o">=</span>zk://hadoop-namenode:2181/mesos
</span></code></pre></td></tr></table></div></figure>
</notextile>
</div>
<p>
<small><em>Figure 2. Mesosphere Spark configuration: First, specify the location of the libmesos.so library. Second, define the URI for the Spark executor, which the Mesos slaves will run. Then define the URIs for the Zookeeper masters.</em></small>
</p>

<p>Once configured, the Spark client can use Mesos as its master, as the <a href="http://people.apache.org/~tdas/spark-1.0-docs/python-programming-guide.html">Spark Python programming guide</a> explicitly states:</p>
<blockquote>
<p>spark-submit supports launching Python applications on standalone, Mesos or YARN clusters, through its <code>--master</code> argument. However, it currently requires the Python driver program to run on the local machine, not the cluster</p>
</blockquote>
<p>This setup should work great for vanilla Spark, but what about our interest in using PySpark with nonstandard Python modules like <a href="http://pandas.pydata.org">Pandas</a> or <a href="http://www.numpy.org">Numpy</a>? As was the impetus for our <a href="https://github.com/Lab41/ipython-spark-docker">ipython-spark-docker</a> project, that would require getting all the right, compatible Python packages to each slave. It looks like using Mesos gets right back to the starting point, where we’d need to do one of the following to make sure each slave has all the right Python packages:</p>
<ul>
<li>Install Python and all required packages on each slave. Luckily, to manage versions and environments, you can <a href="https://mail-archives.apache.org/mod_mbox/spark-user/201409.mbox/%3CCA+2Pv=gmbFNXxPLxL6xu2hNvsWpLtqnQVfvXwhPfUMtC9NzUWw@mail.gmail.com%3E">use Anaconda on each machine</a> if you didn’t want to do system-wide installs.</li>
<li>Use the Spark <code>--py-files</code> option to <a href="http://qnalist.com/questions/4986490/numpy-pyspark">distribute Python packages via egg/zip files</a>. When I attempted this before with Spark standalone mode, I encountered a few difficulties: 1) finding the right packaged module; 2) distributing the modules to all slaves when starting the Spark cluster. I’m sure that has a lot to do with my relative Spark inexperience and interest in having so many Python modules available. Either way, this isn’t a path I plan to revisit.</li>
</ul>
<p>Making a long story short, things aren’t straightforward for getting our desired IPython-driven Spark setup working with Mesos out of the box. So what to do?</p>
<p>Just like before, this desire for portability and repeatability leads to Docker. Since there are several ways to combine these systems, I’ll next walk through three potential architectures for deployment.</p>
<h4 id="option-1-bare-metal-with-a-dash-of-container">Option 1: Bare-metal with a dash of container</h4>
<p>Our first thought for <em>Mesosizing</em> a Dockerized Spark setup was to just install Mesos on bare-metal. Given a vanilla Mesos installation, the Mesos master should be able to accept Spark jobs, send them to the slave nodes, and hosts would then run containerized Spark workers. Voila, distributed analysis! Easy, right?</p>
<p>Not so fast. As near as I can tell, it might not be that straightforward to run Mesos on bare metal as the master for our containerized Spark in cluster mode. Our current Spark worker containers are configured for Spark standalone mode, where the workers register with a Spark master node when launched. Using Mesos as the master would require Mesos to launch the Spark worker containers as task executors. Luckily, Mesos v0.20.1 <a href="https://spark.apache.org/docs/latest/running-on-mesos.html#mesos-docker-support">added the following magic</a>:</p>
<blockquote>
<p>Spark can make use of a Mesos Docker containerizer by setting the property spark.mesos.executor.docker.image in your <a href="https://spark.apache.org/docs/latest/configuration.html#spark-properties">SparkConf</a>. The Docker image used must have an appropriate version of Spark already part of the image, or you can have Mesos download Spark via the usual methods.</p>
</blockquote>
<p>That suggests it might be possible to extend our Spark worker image to include Mesos libraries, point our IPython-Spark client container at Mesos, and configure Spark to launch worker containers to execute Spark tasks. If this option works, it could be a solid way to benefit from Mesos and use our desired Python ecosystem inside Spark worker containers. It could also avoid all the network routing we needed for standalone mode.</p>
<p>Just in case this option has unforeseen issues, or in case we want to consider an alternate architecture in the future, there seem to be two additional options for combining Spark, Mesos, and Docker.</p>
<h4 id="option-2-one-happy-container">Option 2: One happy container</h4>
<p>As outlined above, putting Spark inside Docker provides the ability to quickly spin up and teardown a Spark cluster. To build on that key benefit, it seems like the next step would be to consider a Dockerized Mesos setup similar to our standalone version of Spark-in-Docker containers. But those Mesos containers, of course, also need to include all the requisite Spark and Python libraries, which makes for a pretty beefy container.</p>
<p>Although overloading one Docker image makes me uneasy, I’m wondering if that would deliver a highly portable option for using Spark with Mesos on top of Docker. After all, it should be technically feasible to build a set of master and slave/worker containers that include both Spark and Mesos. Each container would then have all the necessary packages, configurations, and versions. The last step—shuttling communication between hosts and containers—would repeat the network routing work outlined in our <a href="http://lab41.github.io/blog/2015/04/13/ipython-on-spark-on-docker">last post</a>, leading to a similar situation where each host runs one container and “transparently” routes traffic among the cluster hosts and containers.</p>
<p>If we did pursue the <em>Path to Mordor</em> (i.e. “one container to rule them all”), we could build on top of the heavy lifting others have already done to Dockerize Mesos. For example, this <a href="https://medium.com/@gargar454/deploy-a-mesos-cluster-with-7-commands-using-docker-57951e020586">article</a> and <a href="https://github.com/sekka1/mesosphere-docker">related GitHub repo</a> looks like a solid way to “<em>launch a fault tolerant multi node cluster with about seven Docker commands</em>.” Merging this with our existing repo would take some effort, but we should be able to leverage prior work by adding libraries and configuring host-container routing.</p>
<p>That path is not without its perils, however. Cramming several frameworks into one container could become a slippery slope. As our containerized Spark project demonstrated, network routing (i.e. container1-&gt;host1-&gt;host2-&gt;container2) also isn’t the most straightforward undertaking. Adding Mesos into the mix only complicates matters.</p>
<div class="margin-bottom-medium">
<a class="fancybox-effects-a"  href=/images/post_12_mesos/mesos_docker_stack.png><img src="/images/post_12_mesos/mesos_docker_stack.png" title="ipython-spark-docker Plus Mesos" ></a>
</div>
<p>
<small><em><em>Figure 3</em>: Concept architecture for incorporating Mesos into the existing Docker image</em></small>
</p>


<h4 id="option-3-the-sort-of-standalone-deployment">Option 3: The (sort of) standalone deployment</h4>
<p>Faced with the previous two options (everything in one container or just using Spark worker containers), our team brainstormed a possible third choice. As outlined above, Mesos can <a href="http://mesos.apache.org/documentation/latest/docker-containerizer/">launch tasks that contain Docker images</a>. Further, <a href="https://mesosphere.github.io/marathon/">Marathon</a> is a Mesos framework designed specifically to launch long-running applications using containers. So instead of putting Mesos+Spark into one container, and instead of deploying things on bare metal, could we try <a href="https://mesosphere.github.io/marathon/docs/native-docker.html">Running Docker Containers on Marathon</a>? Therefore, instead of using the Mesos master to distribute Spark jobs to Mesos slaves, Marathon might be able to run the standalone ipython-spark-docker cluster <em>as a service inside of Mesos</em>. I haven’t seen anyone try this specific setup with Spark (and maybe for good reason), but it should be possible for Mesos to spawn Spark containers that would look, feel, and act like a standalone Spark cluster.</p>
<p>One downside of this approach is that we would probably lose some of the efficiencies gained by using Mesos as Spark’s master. Second, it would require the Mesos slaves to redirect a large portion of host ports to the Spark containers, which could break Mesos communication patterns or initiate dominos of errors that could be hard to debug. On that latter point, the standard ports for Mesos (5050/5051), Zookeeper (2181,2888,3888,…) and Marathon (customizable) do not appear to overlap with Spark, giving me hope that network routing might actually be possible. At this point, the only way to know for sure might be to try and see what works and where things break.</p>
<div class="margin-bottom-medium">
<img src="/images/post_12_mesos/mesos_spark_standalone.png" title="Standalone Spark within Mesos" >
</div>
<p>
<small><em><em>Figure 4</em>: Concept architecture for running Dockerized Spark in standalone mode within a Mesos cluster</em></small>
</p>


<h3 id="the-path-forward">The path forward</h3>
<p>The best path forward probably depends on specific needs for using Mesos with Spark with Docker. If Mesos can launch our Spark worker containers, keeping Mesos on metal would position it squarely as a piece of infrastructure and launch Spark jobs as an application (as intended). For those interested in maximizing benefits from Docker, the idea of containerizing Spark, Mesos, and all associated libraries should make it possible to quickly deploy (and/or rebuild) a cluster. On the other hand, despite the efficiencies gained through Mesos, adding several frameworks to one Docker container feels a bit messy. If that is too much, using Marathon to run the Standalone Spark containers as a service might be the option to consider.</p>
<p>Overall, it seems worthwhile to experiment and see where things fall over. We’d be interested in knowing whether anyone else has figured out a way to containerize both Mesos and Spark in a multi-node cluster. As of now, we plan to do the following:</p>
<ol type="1">
<li>Get the <a href="https://github.com/sekka1/mesosphere-docker">multi-node Mesos-in-Docker</a> up and running on a few of our OpenStack nodes. We could just as easily try to install Mesos on metal, but I want to give that project a test drive.</li>
<li>Test how easy it is for Mesos to launch our Spark worker containers to execute Spark jobs.</li>
<li>See if we can use Mesos to spin up the <a href="https://github.com/Lab41/ipython-spark-docker">ipython-spark-docker</a> master and worker images to create a standalone Spark cluster within Mesos.</li>
<li>Poke around to see what it would take to run an IPython-on-Spark-on-Mesos set of containers.</li>
</ol>
<p>Stay tuned for a follow-up post after I finish the above steps. Until then, thanks for reading!</p></div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Kyle Foster</span></span>

      








  


<time datetime="2015-07-28T12:00:00+00:00" pubdate data-updated="true">Jul 28<span>th</span>, 2015</time>
      


    </p>
    
      <div class="sharing">
  
  <a href="http://twitter.com/share" class="twitter-share-button" data-url="http://lab41.github.io/blog/2015/07/28/triplewide-trailer-looking-to-rig-ipython/" data-via="" data-counturl="http://lab41.github.io/blog/2015/07/28/triplewide-trailer-looking-to-rig-ipython/" >Tweet</a>
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2015/04/13/ipython-on-spark-on-docker/" title="Previous Post: Using Docker to Build an IPython-driven Spark Deployment">&laquo; Using Docker to Build an IPython-driven Spark Deployment</a>
      
      
    </p>
  </footer>
</article>

</div>

<aside class="sidebar">
  
    <section>
  This project is maintained by the <a href="https://github.com/LAB41">Lab41</a> Team to serve as a platform of discussion on technology topics relevant to Lab41 Challenges. More information about Lab41 can be found at <a href="http://www.lab41.org">www.lab41.org</a>.
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2015/07/28/triplewide-trailer-looking-to-rig-ipython/">Triplewide Trailer, Part 1</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/04/13/ipython-on-spark-on-docker/">Using Docker to Build an IPython-driven Spark Deployment</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/03/13/skyline/">Introducing...SKYLINE</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/02/04/circulo-community-detection/">Circulo: A Community Detection Evaluation Framework</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/12/18/rolx-discovering-individuals-roles-in-a-social-network/">Beyond Community Detection - RolX</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating...</li>
  </ul>
  
  <a href="https://github.com/lab41">@lab41</a> on GitHub
  
  <script type="text/javascript">
   (function($) {
    $(document).on('ready', function() {
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'lab41',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
   })(jQuery);
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>

<section>
  <h1>Blog Authors</h1>
  <ul id="blog_authors">
    

    

    

    

    

    

    

    

    

    

    

    

    

    
    <li><a href="https://github.com/kylef-lab41" target="_blank">Kyle Foster</a></li>
    <li><a href="https://github.com/aganeshLab41" target="_blank">Abhinav Ganesh</a></li>
    <li><a href="https://github.com/ks-lab41" target="_blank">Kabir Soorya</a></li>
    <li><a href="https://github.com/Lab41PaulM" target="_blank">Paul Mazzuca</a></li>
    <li><a href="https://github.com/ymt123" target="_blank">Yonas Tesfaye</a></li>
    <li><a href="https://github.com/nadesai" target="_blank">Nikhil Desai</a></li>
    <li><a href="https://github.com/cglewis" target="_blank">Charlie Lewis</a></li>
    <li><a href="https://github.com/ostrowr" target="_blank">Robbie Ostrow</a></li>
    <li><a href="https://github.com/karkumar" target="_blank">Karthik Ramachandran</a></li>
  </ul>
</section>




  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015 - Lab41 -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a>. Design by <a href="http://octopressthemes.com">Octopress Themes</a>.</a></span>
  <br>
  <span>
    Background image: <a href="https://www.flickr.com/photos/vkurland/8219699128">"Stanford Dish hiking trail"</a> by <a href="https://www.flickr.com/photos/vkurland/">Vadim Kurland</a>, used under <a href="https://creativecommons.org/licenses/by/2.0">CC BY 2.0</a> / Desaturated from original
  </span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'https://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
