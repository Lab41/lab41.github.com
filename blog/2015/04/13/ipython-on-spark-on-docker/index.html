
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Using Docker to Build an IPython-driven Spark Deployment - { lab41 }</title>
  <meta name="author" content="Lab41">

  
  <meta name="description" content="TL;DR: Our ipython-spark-docker repo is a way to deploy an Apache Spark cluster driven by IPython notebooks, running Docker containers for each &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://lab41.github.io/blog/2015/04/13/ipython-on-spark-on-docker/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="{ lab41 }" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="https://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="/stylesheets/custom/bootstrap.min.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="/stylesheets/custom/bootstrap-responsive.min.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="/stylesheets/custom/jquery.fancybox.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="/stylesheets/custom/jquery.fancybox-extra.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="/stylesheets/custom/jquery.fancybox-buttons.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="/stylesheets/custom/jquery.fancybox-thumbs.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="/stylesheets/tables.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="/stylesheets/custom/kronecker.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="https://code.jquery.com/ui/1.10.3/themes/smoothness/jquery-ui.min.css" rel="stylesheet" type="text/css"/>

<script src="/javascripts/jquery-1.9.0.min.js" type="text/javascript"></script>

<script src="/javascripts/fancybox/jquery.fancybox.js" type="text/javascript"></script>
<script src="/javascripts/fancybox/jquery.fancybox-activate.js" type="text/javascript"></script>
<script src="/javascripts/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>
<script src="/javascripts/fancybox/jquery.fancybox-buttons.js" type="text/javascript"></script>
<script src="/javascripts/fancybox/jquery.fancybox-media.js" type="text/javascript"></script>
<script src="/javascripts/fancybox/jquery.fancybox-thumbs.js" type="text/javascript"></script>
<script src="/javascripts/jquery.mousewheel-3.0.6.pack.js" type="text/javascript"></script>
<script src="/javascripts/r_syntax.js" type="text/javascript"></script>
<script src="/javascripts/google_analytics.js" type="text/javascript"></script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/d3/2.10.0/d3.v2.min.js"></script>
<script src="https://code.jquery.com/ui/1.10.3/jquery-ui.min.js"></script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script>
<script src="/javascripts/mathjax.js" type="text/x-mathjax-config"></script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<script type="text/javascript" src="/javascripts/kroneckerapp.js"></script>

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-40906884-1, UA-40464073-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/"><img src="/images/lab41/logo.png" width="212" height="50" alt='Logo' %}> { blog }</a></h1>
  
    <h2>innovation through collaboration</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:lab41.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h3 class="entry-title">Using Docker to Build an IPython-driven Spark Deployment</h3>
    
    
    
    
      <p class="meta">
        








  


<time datetime="2015-04-13T11:11:00+00:00" pubdate data-updated="true">Apr 13<span>th</span>, 2015</time>
        
  

<span class="byline author vcard"> - <span class="fn">Kyle Foster</span></span>

        
        
      </p>
    
  </header>


<div class="entry-content"><table class="table-transparent">
  <tr>
    <td width="25%">
<img src="/images/post_11_docker/ipython-spark-docker.png" title="IPython+Spark+Docker Awesomeness" >
</td>
    <td>
<span style="margin-right: 20px">TL;DR:</span> Our <a href="https://github.com/Lab41/ipython-spark-docker">ipython-spark-docker</a> repo is a way to deploy an <a href="https://spark.apache.org">Apache Spark</a> cluster driven by <a href="http://ipython.org">IPython</a> notebooks, running <a href="https://www.docker.com">Docker</a> containers for each component. The project uses Bash scripts to build each node type from a common Docker image that contains all necessary packages, enables data access from a Hadoop cluster, and runs on dedicated hosts. By using IPython as the interface, you can leverage a variety of data processing, machine learning, and visualization tasks using the following tools and libraries:
</td>
  </tr>
</table>

<table class="table-transparent table-centered margin-bottom-large font-size-small">
  <tr>
    <td>
<a href="http://hadoop.apache.org/" target="_blank">HDFS</a>
</td>
    <td>
<a href="http://hbase.apache.org/" target="_blank">Hbase</a>
</td>
    <td>
<a href="https://hive.apache.org/" target="_blank">Hive</a>
</td>
    <td>
<a href="http://oozie.apache.org/" target="_blank">Oozie</a>
</td>
    <td>
<a href="http://pig.apache.org/" target="_blank">Pig</a>
</td>
    <td>
<a href="http://gethue.com/" target="_blank">Hue</a>
</td>
    <td></td>
  </tr>
  <tr>
    <td>
<a href="http://pandas.pydata.org" target="_blank">Pandas</a>
</td>
    <td>
<a href="http://nltk.org" target="_blank">NLTK</a>
</td>
    <td>
<a href="http://www.numpy.org" target="_blank">NumPy</a>
</td>
    <td>
<a href="http://scipy.org" target="_blank">SciPy</a>
</td>
    <td>
<a href="http://sympy.org" target="_blank">SymPy</a>
</td>
    <td>
<a href="http://scikit-learn.org/" target="_blank">Scikit-Learn</a>
</td>
  </tr>
  <tr>
    <td>
<a href="http://cython.org" target="_blank">Cython</a>
</td>
    <td>
<a href="http://numba.pydata.org" target="_blank">Numba</a>
</td>
    <td>
<a href="http://biopython.org" target="_blank">Biopython</a>
</td>
    <td>
<a href="http://zeromq.org/bindings:python" target="_blank">0MQ</a>
</td>
    <td>
<a href="http://www.clips.ua.ac.be/pattern" target="_blank">Pattern</a>
</td>
    <td>
<a href="http://stanford.edu/~mwaskom/software/seaborn/" target="_blank">Seaborn</a>
</td>
  </tr>
  <tr>
    <td>
<a href="http://matplotlib.org/" target="_blank">Matplotlib</a>
</td>
    <td>
<a href="http://statsmodels.sourceforge.net/" target="_blank">Statsmodels</a>
</td>
    <td>
<a href="http://www.crummy.com/software/BeautifulSoup/" target="_blank">Beautiful Soup</a>
</td>
    <td>
<a href="https://networkx.github.io/" target="_blank">NetworkX</a>
</td>
    <td>
<a href="http://numba.pydata.org/" target="_blank">LLVM</a>
</td>
    <td>
<a href="http://mdp-toolkit.sourceforge.net/" target="_blank">MDP</a>
</td>
  </tr>
  <tr>
    <td>
<a href="http://bokeh.pydata.org/" target="_blank">Bokeh</a>
</td>
    <td>
<a href="https://github.com/wrobstory/vincent" target="_blank">Vincent</a>
</td>
  </tr>
</table>



<h3 id="generating-a-few-amps">Generating a few amps</h3>
<p>Here at <a href="http://www.lab41.org">Lab41</a>, we build open source prototypes using the latest big data, infrastructure, and data science technologies. In a perfect world, these tools would magically work together. The reality is that they usually require a lot of effort just to install and configure properly. And when someone else comes along to actually use them — especially if they are a newly-minted teammate or someone unfamiliar with the myriad command-line switches and gotchas — the experience can transform these tools into shark repellent for sysadmins and end users alike.</p>
If the above sounds familiar, or if you’re interested in using IPython notebooks to perform non-trivial<span style="color: #C30017">*</span> data analytics with Apache Spark, then please continue…
<div class="margin-bottom-large" style="color: #AAA; text-align: right">
<small><span style="color: #C30017">*</span>defined roughly as being able to use data in our 32-node Hadoop cluster</small>
</div>
<h4 id="sparked-interest">Sparked interest</h4>
<p>This effort started when I became interested in Apache Spark, which has quickly become the heir apparent to MapReduce’s big data throne. By most measures, this data processing engine is living up to claims of <a href="https://spark.apache.org/news/spark-wins-daytona-gray-sort-100tb-benchmark.html">better performance</a> and usable APIs for <a href="https://spark.apache.org/mllib">powerful algorithmic libraries</a>. If you add in its support for interactive and iterative development, plus use of data-scientist- and developer-friendly languages like Python, it’s no surprise why so many have fallen for this relative newcomer.</p>
<p>Out of the box, Spark includes a number of powerful capabilities, including the ability to write SQL queries, perform streaming analytics, run machine learning algorithms, and even tackle graph-parallel computations. Those features enable Spark to compete with a number of tools from mature ecosystems like Hadoop, but what really stands out is its usability. In short, incorporating interactive shells (in both Scala and Python) presents an approachable way to kick the tires. In my book, that’s a huge win that should help pull in curious developers (like me). After going through Spark’s cut-and-paste <a href="https://spark.apache.org/examples.html">examples</a>, as well as a <a href="http://mbonaci.github.io/mbo-spark">few</a> <a href="http://www.michael-noll.com/blog/2014/10/01/kafka-spark-streaming-integration-example-tutorial">more involved</a> <a href="http://blog.cloudera.com/blog/2014/04/how-to-run-a-simple-apache-spark-app-in-cdh-5">tutorials</a>, I had seen enough to want to begin using this platform. Anticipating the rest of our team benefiting from its capabilities, I also became interested in enabling their data analysis needs.</p>
<h3 id="usability-a-driving-need">Usability a driving need</h3>
<p>Within our team, we have developers, data scientists, and analysts with varying skills and experiences. Providing a solution that everyone could use was a key goal, which led to the following objectives:</p>
<ul>
<li>We needed the Spark cluster to handle decent-sized workloads. Our 32-node Hadoop cluster is a representative size.</li>
<li>We needed an “easy-to-use” interface and language bindings that everyone would have a shot at learning. Python would be good. Something with collaboration features that wasn’t driven by the command line would be great.</li>
<li>We needed to run analytics against “non-trivial” data, which I’ll define as being able to access and process data from our Hadoop cluster.</li>
</ul>
<p>After giving it some thought, I realized IPython would address that short list nicely and would be a familiar interface for our team. I decided to try to build something that looks like:</p>
<div class="margin-bottom-medium">
<img src="/images/post_11_docker/architecture-v1-draw.io.png" title="Overview of IPython-Spark-HDFS concept" >
</div>
Definitions
<ul>
  <li>
<strong>Spark Master</strong>: the Spark node that receives jobs, organizes the workflow, and doles out work
</li>
  <li>
<strong>Spark Worker</strong>: <em>N</em> number of Spark nodes that receive work tasks from the master and do the actual analysis
</li>
  <li>
<strong>IPython Driver</strong>: the process running the application’s main function; the Python shell in “client” mode submits from outside the cluster, which is why I refer to it as the <em>remote client</em> and <em>client driver</em>
</li>
</ul>


<h3 id="a-straightforward-path">A straightforward path?</h3>
<p>The first step, deploying the Spark cluster, seemed trivial since Lab41 uses a CDH5 cluster and Cloudera includes Spark in their distribution. However, I also had to develop around the situation where end users won’t be able to login/SSH directly to the Spark cluster for their analytics. Most of our partners are very security-conscious, so adding a client node that can remotely connect and drive analytics on the cluster became the next must-have. “<em>Easy</em>,” I thought. “<em>I’ll just setup a remote node to drive Spark analysis within the cluster</em>.” I assumed the steps would be straightforward (and probably already solved):</p>
<ol type="1">
<li>Start the master</li>
<li>Connect workers to the master node</li>
<li>Configure a remote client connected to the master</li>
<li>Deploy an IPython notebook server on the client</li>
</ol>
<p>Starting the master and worker nodes in our CDH5 cluster via the <a href="http://www.cloudera.com/content/cloudera/en/documentation/cloudera-manager/v4-latest/Cloudera-Manager-Installation-Guide/cmig_spark_installation_standalone.html">Cloudera Manager</a> <em>was</em> straightforward. Building a client node also was easy since the Spark team graciously provides several source and pre-built packages for several recent releases. With a straightforward download and install, my client was ready to drive the cluster.</p>
<p>To initially test the client driver — considering the end goal was to use IPython — I decided to start with a <code>pyspark</code> shell connected to the master (I decided to hold off on IPython integration to isolate any potential misconfigurations). Based on tutorials, connecting the remote client to the cluster initially appeared as easy as specifying <code>./bin/pyspark --master spark://ip:port</code>. However, I immediately ran into a couple errors related to library mismatches:</p>
<div class="bogus-wrapper">
<notextile>
<figure class='code'><figcaption>
<span></span>
</figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>incompatible spark driver - java.io.InvalidClassException: org.apache.spark.deploy.ApplicationDescription; <span class="nb">local </span>class incompatible: stream classdesc <span class="nv">serialVersionUID</span> <span class="o">=</span> 583745679236071411, <span class="nb">local </span>class <span class="nv">serialVersionUID</span> <span class="o">=</span> 7674242335164700840
</span></code></pre></td></tr></table></div></figure>
</notextile>
</div>
<div class="bogus-wrapper">
<notextile>
<figure class='code'><figcaption>
<span></span>
</figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>java.lang.ClassCastException <span class="o">(</span>cannot assign instance of org.apache.spark.rdd.RDD<span class="nv">$$</span>anonfun<span class="nv">$17</span> to field org.apache.spark.SparkContext<span class="nv">$$</span>anonfun<span class="nv">$runJob$4</span>.func<span class="nv">$1</span> of <span class="nb">type </span>scala.Function1 in instance of org.apache.spark.SparkContext<span class="nv">$$</span>anonfun<span class="nv">$runJob$4</span><span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>
</notextile>
</div>
<p>After a few rounds of Googling, I found out these errors are caused by using incompatible spark driver libraries. Understandably, the client driver node needs to use libraries compatible with our cluster nodes, whereas the driver’s v1.2.<span style="color: #C30017; font-weight: bold">1</span> was apparently incompatible with our cluster’s v1.2.<span style="color: #C30017; font-weight: bold">0</span>. With that quick reminder to always verify build versions, I downloaded and installed the correct one on the client. Problem fixed!</p>
<h4 id="down-the-rabbit-hole-i-went">Down the rabbit hole I went…</h4>
<p>With those library mismatch errors behind me, I soon encountered another error:</p>
<div class="bogus-wrapper">
<notextile>
<figure class='code'><figcaption>
<span></span>
</figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
</span></code></pre></td></tr></table></div></figure>
</notextile>
</div>
<p>These kinds of errors scare me more than most since they give just enough to identify the general cause (“registering” the client and/or workers), but not enough to figure out exactly where to look. After poking around the server and worker logs (<code>/var/log/spark/spark-&lt;master|worker&gt;-&lt;hostname&gt;.log</code>), it looked like the client successfully connected to the master, but something after that failed to complete the Spark initialization. Errors like the following highlighted that it had something to do with my network configuration:</p>
<div class="bogus-wrapper">
<notextile>
<figure class='code'><figcaption>
<span></span>
</figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>WARN Remoting: Tried to associate with unreachable remote address <span class="o">[</span>akka.tcp://sparkDriver@sandbox:41615<span class="o">]</span>. Address is now gated <span class="k">for </span>60000 ms, all messages to this address will be delivered to dead letters.
</span></code></pre></td></tr></table></div></figure>
</notextile>
</div>
<p>Since “unreachable addresses” can of course be caused by several factors, I’ll save you the nitty-gritty and jump straight to the important point: connecting a remote client node requires several expected and non-obvious network settings:</p>
<ul>
<li><strong>Expected Node-to-Node Communication</strong>: The master and workers must be reachable. This requirement is satisfied by several <a href="http://spark.apache.org/docs/1.2.1/spark-standalone.html">well-documented</a> configurations:
<ul>
<li>Firewall rules must allow traffic to the Spark service (default: 7077 for master, random for worker)</li>
<li>Firewall rules must allow traffic to the Spark UIs (default: 8080 for master, 8081 for worker)</li>
</ul></li>
<li><strong>Unexpected Cluster-&gt;Driver Communication</strong>: From the <a href="http://spark.apache.org/docs/1.2.1/security.html">Configuring Ports for Network Security</a> page, notice how important things such as communicating state changes and serving files require connections from the Spark nodes <strong>to</strong> the driver on a <strong>random</strong> port. That architecture means the remote client node is opening randomly-selected ports for callback from nodes in the Spark cluster. This design forces two important updates to our network communication:
<ul>
<li>Firewall rules must allow traffic from the Spark master and workers to a range of random ports on the client</li>
<li>The client must be network-addressable by master and worker nodes, which means the <code>tcp://sparkDriver</code> above needed to be a fully-qualified domain name (FQDN) on the network.</li>
</ul></li>
</ul>
<h3 id="compatibility-is-key">Compatibility is key</h3>
<p>Whereas I could easily open the potential range of random ports on master, worker, and client nodes, adding a network-addressable client to the cluster felt like a step too far for this initial test setup. At this point, I decided to stop using our primary Hadoop cluster and instead virtualize a test Spark cluster within our internal instance of <a href="https://www.openstack.org">OpenStack</a>. As before, using the pre-built Spark packages made it easy to create master and worker nodes for a standalone Spark installation. Running the startup scripts <code>./sbin/start-&lt;master|slaves|all&gt;.sh</code> fired up and registered the master and workers, providing me with a throwaway cluster I could use for experimentation more comfortably.</p>
<p>I now had spun up a small virtualized Spark cluster, added a client node on the network, ensured it was reachable with a FQDN, and opened all necessary OpenStack security rules and ports for each node. For good measure I ensured each node’s <code>/etc/hosts</code> contained entries for the cluster’s nodes (i.e. <code>10.1.2.3 spark-node1.internal-domain</code>), leaving me confident all necessary traffic would reach its intended destination.</p>
<p>With the network configurations behind me, the quest led me into another set of library mismatch errors:</p>
<div class="bogus-wrapper">
<notextile>
<figure class='code'><figcaption>
<span></span>
</figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>INFO scheduler.TaskSetManager: Lost task 613.3 in stage 0.0 <span class="o">(</span>TID 2261<span class="o">)</span> on executor spark-node1.internal-domain: java.io.IOException <span class="o">(</span>Cannot run program <span class="s2">&quot;python2.7&quot;</span>: <span class="nv">error</span><span class="o">=</span>2, No such file or directory<span class="o">)</span>
</span></code></pre></td></tr></table></div></figure>
</notextile>
</div>
<p>“<em>Hmmm, strange</em>,” I thought. “<em>All of my OpenStack images include Python…what’s the deal?</em>” Well, when I provisioned the OpenStack instances, I used different host images for the cluster nodes and client driver as a way to better mimic that real-world possibility. It turns out the older worker/client nodes had python2.6, whereas the client (and Spark’s default options) explicitly specify python2.7. Updating the client environment to <code>export PYSPARK_PYTHON=python</code> propagated Spark’s configuration and let each node rely on their native python build. This situation clearly won’t work for a production deployment, but I was at the stage of wanting to move past errors and could later re-build environments and configurations.</p>
<p>Next, I ran into the strange situation where my client would accept the examples I had created, but when it submitted jobs to workers, they seemed to be missing things and would fail with messages such as:</p>
<div class="bogus-wrapper">
<notextile>
<figure class='code'><figcaption>
<span></span>
</figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>ImportError: No module named numpy
</span></code></pre></td></tr></table></div></figure>
</notextile>
</div>
<p>and</p>
<div class="bogus-wrapper">
<notextile>
<figure class='code'><figcaption>
<span></span>
</figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='sh'><span class='line'>version <span class="s1">&#39;GLIBC_2.14&#39;</span> not found
</span></code></pre></td></tr></table></div></figure>
</notextile>
</div>
<p>Of course! In my previous rounds of <a href="http://www.hanselman.com/blog/YakShavingDefinedIllGetThatDoneAsSoonAsIShaveThisYak.aspx">yak-shaving</a> fixes, I forgot one obvious requirement: All Spark nodes clearly need the same/compatible environment to effectively distribute analysis (aka “not fail”) across the cluster. It wasn’t sufficient to add things like <code>numpy</code> and <code>GLIBC</code> to my client; every node in the Spark cluster also needed those same modules and libraries.</p>
<h4 id="whale-of-a-pivot">Whale of a pivot</h4>
<p>I made a crucial decision at this point. I did not like the idea of continuing to tweak and tune the configurations, environments, and libraries for each master, worker, and client hosts. While I was beginning to understand things, I knew nobody else would be able (or want) to replicate my work. If only there was a technology focused on transparent repeatability and portability of infrastructure…</p>
<p>Enter <a href="https://www.docker.com">Docker</a>!</p>
<p>Yes, the fantastic “build once, run anywhere” container not only enables development of portable apps, but also can be a godsend to sysadmins in this type of situation. From their website:</p>
<blockquote>
<p>Sysadmins use Docker to provide standardized environments for their development, QA, and production teams, reducing “works on my machine” finger-pointing. By “Dockerizing” the app platform and its dependencies, sysadmins abstract away differences in OS distributions and underlying infrastructure.</p>
</blockquote>
<p>Perfect! This benefit, I knew, would enable me to package all the configuration options within a common environment I could then deploy as master, worker, and client nodes. <em>Caveat emptor</em>, though. I have used Docker enough to know my intended IPythonized-Spark (or is it Sparkified-IPython?) setup would require a decent amount of customization, especially the network configuration pieces. But I also knew it was possible, and since a combination of Dockerfiles and scripting would lead to a repeatable build, I made the call to Dockerize the entire setup.</p>
<h3 id="dockerization">Dockerization</h3>
<p>Since others already figured out how to run Spark in Docker, I first turned to those <a href="https://github.com/sequenceiq/docker-spark">images</a> and <a href="https://github.com/amplab/docker-scripts">tutorials</a>. After using them, I learned a few important things:</p>
<ol type="1">
<li>The images usually run the entire Spark cluster in a single container, which is great for kicking the tires, but not realistic for running actual workloads. I needed to run each master/worker/client as a separate container, ideally with each on a dedicated node to support large workloads.</li>
<li>The images usually include default configurations for accessing Hadoop nodes that spin up within the container. While I could manually specify the longhand <code>hdfs://&lt;hadoop-namenode&gt;/path/to/hdfs/file</code> to access our Hadoop cluster, I’m lazy and wanted our <code>hadoop-namenode</code> to serve as the container’s default HDFS endpoint. To enable that default connectivity, I added our Hadoop configuration to the container. As an added measure for data locality, the ideal deployment would run these containers inside our Hadoop nodes and thereby avoid sending large amounts of data across the network. Keep in mind this setup means you’ll have to ensure library version compatibility between the containers and your Hadoop nodes.</li>
<li>When run, the default Docker option sets each container’s hostname to its container ID, which causes issues related to Spark’s use of FQDN for network traffic. For example, a hostname of <code>d5d3225d06c4</code> would cause Spark workers to attempt sending traffic to that host, which of course wouldn’t exist on the network. By passing the host node’s hostname to the container at runtime, the container effectively “thinks” it is the host and can broadcast the appropriate destination address.</li>
<li>The images provide a very basic Python environment. We need several additional data wrangling, machine learning, and visualization tools.</li>
<li>They’ve all done great work I can build on for our needs.</li>
</ol>
Refining my original architecture, I was looking to build something like:
<div>
<img src="/images/post_11_docker/architecture-v2-draw.io.png" title="Refined concept for IPython-Spark-HDFS using Docker" >
</div>
<p>
<small><em>Refined concept for IPython-Spark-HDFS using Docker</em></small>
</p>

<h4 id="the-base-image">The base image</h4>
<p>Since I’ve used similar bits and pieces in other work, I knew where I wanted to start for building the foundation. I started with the following Docker images:</p>
<ul>
  <li>
<a href="https://registry.hub.docker.com/u/richhaase/cdh5-hadoop/">richaase/cdh5-hadoop</a>: The base image contains CDH5 (Cloudera Distribution for Apache Hadoop 5) installed on Ubuntu 14.04 with Oracle JDK7. I added configuration files to access a remote HDFS cluster. Among other things, they include the following tools and libraries:
<table class="table-transparent table-centered margin-bottom-medium">
      <tr>
        <td>
<a href="http://hadoop.apache.org/">HDFS</a>
</td>
        <td>
<a href="http://hbase.apache.org/">Hbase</a>
</td>
        <td>
<a href="https://hive.apache.org/">Hive</a>
</td>
        <td>
<a href="http://oozie.apache.org/">Oozie</a>
</td>
        <td>
<a href="http://pig.apache.org/">Pig</a>
</td>
        <td>
<a href="http://gethue.com/">Hue</a>
</td>
      </tr>
    </table>
  </li>

<li>
<a href="https://github.com/mingfang/docker-ipython">mingfang/docker-ipython</a>: The base image runs a robust IPython environment inside Docker, which I tweaked by enabling, disabling, and adding a few Python modules. It adds:
<table class="table-transparent table-centered margin-bottom-medium">
      <tr>
        <td>
<a href="http://pandas.pydata.org" target="_blank">Pandas</a>
</td>
        <td>
<a href="http://nltk.org" target="_blank">NLTK</a>
</td>
        <td>
<a href="http://www.numpy.org" target="_blank">NumPy</a>
</td>
        <td>
<a href="http://scipy.org" target="_blank">SciPy</a>
</td>
        <td>
<a href="http://sympy.org" target="_blank">SymPy</a>
</td>
        <td>
<a href="http://scikit-learn.org/" target="_blank">Scikit-Learn</a>
</td>
      </tr>
      <tr>
        <td>
<a href="http://cython.org" target="_blank">Cython</a>
</td>
        <td>
<a href="http://numba.pydata.org" target="_blank">Numba</a>
</td>
        <td>
<a href="http://biopython.org" target="_blank">Biopython</a>
</td>
        <td>
<a href="http://zeromq.org/bindings:python" target="_blank">0MQ</a>
</td>
        <td>
<a href="http://www.clips.ua.ac.be/pattern" target="_blank">Pattern</a>
</td>
        <td>
<a href="http://stanford.edu/~mwaskom/software/seaborn/" target="_blank">Seaborn</a>
</td>
      </tr>
      <tr>
        <td>
<a href="http://matplotlib.org/" target="_blank">Matplotlib</a>
</td>
        <td>
<a href="http://statsmodels.sourceforge.net/" target="_blank">Statsmodels</a>
</td>
        <td>
<a href="http://www.crummy.com/software/BeautifulSoup/" target="_blank">Beautiful Soup</a>
</td>
        <td>
<a href="https://networkx.github.io/" target="_blank">NetworkX</a>
</td>
        <td>
<a href="http://numba.pydata.org/" target="_blank">LLVM</a>
</td>
        <td>
<a href="http://mdp-toolkit.sourceforge.net/" target="_blank">MDP</a>
</td>
      </tr>
      <tr>
        <td>
<a href="http://bokeh.pydata.org/" target="_blank">Bokeh</a>
</td>
        <td>
<a href="https://github.com/wrobstory/vincent" target="_blank">Vincent</a>
</td>
      </tr>
    </table>
  </li>
</ul>


<h4 id="enhancing-the-base">Enhancing the base</h4>
<p>Borrowing from those two Docker images to build the common base, I layered a few important changes within the Dockerfile:</p>
<ol type="1">
<li>The image downloads updated Spark libraries to the latest pre-built standalone packages.</li>
<li>The image updates Spark configuration options for <code>PYSPARK_PYTHON</code>, <code>SPARK_SSH_PORT</code> and <code>SPARK_SSH_OPTS</code>. The latter two force Spark to communicate on SSH via a non-standard port (I chose 2122). I made this change to the containers’ SSH daemons so I could still SSH in “normally” via port 22 on the host machines.</li>
<li>I added SSH keys to enable Spark master-worker communication, which I <strong>strongly</strong> recommend re-generating before your build if you decide to try.</li>
<li>I added specific configuration details for HDFS access, which you’ll need to update to connect to your cluster.</li>
</ol>
<h4 id="creating-role-based-images">Creating role-based images</h4>
<p>Building on that base image, I created Docker images for each master, worker, and client node types. Each image uses a <code>bootstrap.sh</code> script to start <code>runit</code>, leaving each node type to implement different startup services:</p>
<ul>
<li>The master image runs an SSH daemon and <code>spark-master</code> process. This setup violates Docker’s “one-process-per-container” philosophy, but is necessary since master and workers communicate via SSH (as noted before, via port 2122)</li>
<li>Similarly, the worker images startup an SSH daemon and <code>spark-worker</code> process</li>
<li>The client image runs an IPython notebook using a custom pyspark profile, which I configured by following guides such as <a href="http://blog.cloudera.com/blog/2014/08/how-to-use-ipython-notebook-with-apache-spark">How to use IPython notebook with Apache Spark</a></li>
</ul>
<h4 id="running-the-containers">Running the containers</h4>
<p>I wrote a few Bash scripts to startup each container type. If you plan to use these, keep in mind two important details:</p>
<ul>
<li>Since I wanted each container living on a dedicated node, you’ll have to manually startup each container type within a provisioned node. Within OpenStack, I simply startup each instance with an after-build command to run that node type’s startup script (i.e. <code>./3-run-spark-worker.sh spark://master-fqdn:port</code>). If provisioning on bare metal and/or within your HDFS cluster, you could use something heavyweight like <a href="https://puppetlabs.com">puppet</a>, a lighter deployment tool like <a href="http://flask.pocoo.org/docs/0.10/patterns/fabric">fabric</a>, or even a simple series of <code>ssh -e</code> commands.</li>
<li>Given the required network traffic between master, workers, and client, there is a wide range of default ports that each host needs to forward to its respective container. Simply put, each host needs to transparently forward all Spark ports to its container. I could have achieved this by <code>EXPOSE</code>ing ports in the Dockerfile and later publishing each port/range at runtime, but that method can cause <code>iptables</code> to run out of memory. Plus, it makes the container metadata (and <code>docker ps</code> output) unreadable with so many mapped ports. Instead, I made the host create a new <code>iptables</code> chain with custom <code>PREROUTING</code> rules. If you don’t want <code>iptables</code> as a dependency, or if you just want to handle networking <em>The Docker Way</em>, I would suggest explicitly setting the random ports identified in the <a href="http://spark.apache.org/docs/1.2.1/security.html">Configuring Ports for Network Security</a> guide (i.e. <code>SPARK_WORKER_PORT</code> and <code>spark.driver.port</code>).</li>
</ul>
The end result is: <a class="fancybox-effects-a"  href=/images/post_11_docker/architecture-v3-draw.io.png><img src="/images/post_11_docker/architecture-v3-draw.io.png" title="Docker image and networking for ipython-spark-docker deployment" ></a>
<p>
<small><em>Docker image and networking for ipython-spark-docker deployment</em></small>
</p>

<table class="table-transparent margin-bottom-large">
  <tr>
    <td width="50%">
      
<a class="fancybox-effects-a"  href=/images/post_11_docker/screenshot_wordcount.png><img src="/images/post_11_docker/screenshot_wordcount.png" title="Screenshot of Spark word count example using ipython-spark-docker" ></a>
<div>
<small><em>Spark word count example via IPython</em></small>
</div>
<pre><code>&lt;/td&gt;
&lt;td&gt;
  &lt;a class=&quot;fancybox-effects-a&quot;  href=/images/post_11_docker/screenshot_mllib.png&gt;&lt;img src=&quot;/images/post_11_docker/screenshot_mllib.png&quot; title=&quot;Screenshot of Spark MLlib example&quot; &gt;&lt;/a&gt;
  &lt;div&gt;&lt;small&gt;_Spark MLlib example_&lt;/small&gt;&lt;/div&gt;
&lt;/td&gt;</code></pre>
</tr>
</table>


<h3 id="wrap-up">Wrap-up</h3>
<p>As with most big data platforms, setting up Apache Spark was not a simple “double-click installation” process. It required host and network configurations that sometimes were difficult to find and decipher. Adding my goal of driving analytics with a remote client revealed additional gotchas. I managed to troubleshoot these, but it was an effort that I wouldn’t want others to have to reproduce. The extra desire to leverage IPython’s simpler interface, connect to our HDFS cluster, and ensure library compatibility between all nodes led me to Docker’s doorstep.</p>
<p>While the architecture is complex, Docker made it less complicated and more repeatable to develop, test, document, and iterate. Fast forward to today, we now have a working version of IPython-driven Spark analytics on our HDFS data, which is something others might be looking to use. And rather than say, “<em>Email me for help</em>,” or “<em>Google ‘this’ and StackOverflow ‘that’</em>,” I can point you to <a href="https://github.com/Lab41/ipython-spark-docker">ipython-spark-docker</a> for:</p>
<ol type="1">
<li>A base Docker image that contains all necessary Hadoop, Spark, and Python packages.</li>
<li>Skeleton configuration files for HDFS access.</li>
<li>Separate master, worker, and client images.</li>
<li>Bash scripts to build and run each base/master/worker/client.</li>
<li>End users access and use the entire system through the client container’s IPython notebook.</li>
</ol>
<p>If you’ve read this far, thanks for your patience while I walked you through this end-to-end journey. I came across so many questions online where people ran into similar problems that I wanted to document the entire process. Hopefully, this post will save others from wondering where things might have gone wrong.</p>
<p>If you decide to give our <a href="https://github.com/Lab41/ipython-spark-docker">repo</a> a try, let us know. The Lab is interested in knowing if it helps, and is happy to offer a helping hand if something needs a little more work.</p>
<p>Until our next post, thanks for reading!</p></div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Kyle Foster</span></span>

      








  


<time datetime="2015-04-13T11:11:00+00:00" pubdate data-updated="true">Apr 13<span>th</span>, 2015</time>
      


    </p>
    
      <div class="sharing">
  
  <a href="http://twitter.com/share" class="twitter-share-button" data-url="http://lab41.github.io/blog/2015/04/13/ipython-on-spark-on-docker/" data-via="" data-counturl="http://lab41.github.io/blog/2015/04/13/ipython-on-spark-on-docker/" >Tweet</a>
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2015/03/13/skyline/" title="Previous Post: Introducing...SKYLINE">&laquo; Introducing...SKYLINE</a>
      
      
        <a class="basic-alignment right" href="/blog/2015/07/28/triplewide-trailer-looking-to-rig-ipython/" title="Next Post: Triplewide Trailer, Part 1">Triplewide Trailer, Part 1 &raquo;</a>
      
    </p>
  </footer>
</article>

</div>

<aside class="sidebar">
  
    <section>
  This project is maintained by the <a href="https://github.com/LAB41">Lab41</a> Team to serve as a platform of discussion on technology topics relevant to Lab41 Challenges. More information about Lab41 can be found at <a href="http://www.lab41.org">www.lab41.org</a>.
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2015/07/28/triplewide-trailer-looking-to-rig-ipython/">Triplewide Trailer, Part 1</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/04/13/ipython-on-spark-on-docker/">Using Docker to Build an IPython-driven Spark Deployment</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/03/13/skyline/">Introducing...SKYLINE</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/02/04/circulo-community-detection/">Circulo: A Community Detection Evaluation Framework</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/12/18/rolx-discovering-individuals-roles-in-a-social-network/">Beyond Community Detection - RolX</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating...</li>
  </ul>
  
  <a href="https://github.com/lab41">@lab41</a> on GitHub
  
  <script type="text/javascript">
   (function($) {
    $(document).on('ready', function() {
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'lab41',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
   })(jQuery);
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>

<section>
  <h1>Blog Authors</h1>
  <ul id="blog_authors">
    

    

    

    

    

    

    

    

    

    

    

    

    

    
    <li><a href="https://github.com/kylef-lab41" target="_blank">Kyle Foster</a></li>
    <li><a href="https://github.com/aganeshLab41" target="_blank">Abhinav Ganesh</a></li>
    <li><a href="https://github.com/ks-lab41" target="_blank">Kabir Soorya</a></li>
    <li><a href="https://github.com/Lab41PaulM" target="_blank">Paul Mazzuca</a></li>
    <li><a href="https://github.com/ymt123" target="_blank">Yonas Tesfaye</a></li>
    <li><a href="https://github.com/nadesai" target="_blank">Nikhil Desai</a></li>
    <li><a href="https://github.com/cglewis" target="_blank">Charlie Lewis</a></li>
    <li><a href="https://github.com/ostrowr" target="_blank">Robbie Ostrow</a></li>
    <li><a href="https://github.com/karkumar" target="_blank">Karthik Ramachandran</a></li>
  </ul>
</section>




  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015 - Lab41 -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a>. Design by <a href="http://octopressthemes.com">Octopress Themes</a>.</a></span>
  <br>
  <span>
    Background image: <a href="https://www.flickr.com/photos/vkurland/8219699128">"Stanford Dish hiking trail"</a> by <a href="https://www.flickr.com/photos/vkurland/">Vadim Kurland</a>, used under <a href="https://creativecommons.org/licenses/by/2.0">CC BY 2.0</a> / Desaturated from original
  </span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'https://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
