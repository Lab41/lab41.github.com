
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>{ lab41 }</title>
  <meta name="author" content="Lab41">

  
  <meta name="description" content="Why are data scientists so obsessed with graphs? It’s because graphs are the best tools we have for modeling the real world. By analyzing the graph &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://lab41.github.io/blog/page/6/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="{ lab41 }" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="https://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="/stylesheets/custom/bootstrap.min.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="/stylesheets/custom/bootstrap-responsive.min.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="/stylesheets/custom/jquery.fancybox.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="/stylesheets/custom/jquery.fancybox-extra.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="/stylesheets/custom/jquery.fancybox-buttons.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="/stylesheets/custom/jquery.fancybox-thumbs.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="/stylesheets/tables.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="/stylesheets/custom/kronecker.css" media="screen, projection" rel="stylesheet" type="text/css">
<link href="https://code.jquery.com/ui/1.10.3/themes/smoothness/jquery-ui.min.css" rel="stylesheet" type="text/css"/>

<script src="/javascripts/jquery-1.9.0.min.js" type="text/javascript"></script>

<script src="/javascripts/fancybox/jquery.fancybox.js" type="text/javascript"></script>
<script src="/javascripts/fancybox/jquery.fancybox-activate.js" type="text/javascript"></script>
<script src="/javascripts/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>
<script src="/javascripts/fancybox/jquery.fancybox-buttons.js" type="text/javascript"></script>
<script src="/javascripts/fancybox/jquery.fancybox-media.js" type="text/javascript"></script>
<script src="/javascripts/fancybox/jquery.fancybox-thumbs.js" type="text/javascript"></script>
<script src="/javascripts/jquery.mousewheel-3.0.6.pack.js" type="text/javascript"></script>
<script src="/javascripts/r_syntax.js" type="text/javascript"></script>
<script src="/javascripts/google_analytics.js" type="text/javascript"></script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/d3/2.10.0/d3.v2.min.js"></script>
<script src="https://code.jquery.com/ui/1.10.3/jquery-ui.min.js"></script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script>
<script src="/javascripts/mathjax.js" type="text/x-mathjax-config"></script>
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<script type="text/javascript" src="/javascripts/kroneckerapp.js"></script>

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-40906884-1, UA-40464073-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/"><img src="/images/lab41/logo.png" width="212" height="50" alt='Logo' %}> { blog }</a></h1>
  
    <h2>innovation through collaboration</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:lab41.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h3 class="entry-title"><a href="/blog/2013/08/27/stochastic-kronecker-natural-graphs/">Stochastic Kronecker Natural Graphs</a></h3>
    
    
    
    
      <p class="meta">
        








  


<time datetime="2013-08-27T11:44:00+00:00" pubdate data-updated="true">Aug 27<span>th</span>, 2013</time>
        
        
  

<span class="byline author vcard"> - <span class="fn">Nikhil Desai</span></span>

        
      </p>
    
  </header>


  <div class="entry-content"><p>Why are data scientists so obsessed with graphs? It’s because graphs are the best tools we have for modeling the real world. By analyzing the graph representation of a real-world structure, we can glean a variety of insights about it. Graphs that model real-world phenomena are called “natural” graphs, and a great deal of data science focuses on them. However, obtaining natural graphs is hard; it would be nice if we had a way to generate similar-looking graphs without the data-gathering work. Enter the <strong>stochastic Kronecker graph model</strong>: an easy way to generate almost-natural synthetic graphs. This post will give an overview of natural graphs and describe the stochastic Kronecker model of generating graphs.</p>
<div class="row-fluid">
<h3 style="text-align:center">
Kronecker Visualization
</h3>
</div>
<div class="row-fluid" style="margin-bottom:20px">
  <div class="span12" style="font-size: smaller">
The visualizations below demonstrate the contents of this post. Use the interactive controls to easily create almost-natural synthetic graphs from just a few key parameters:
</div>
</div>
<div class="row-fluid">
  <div class="span6">
    <div>
      
Kronecker Initiation:
<ul style="font-size: smaller">
        <li>
<strong>Initiator matrix</strong>: a two-by-two matrix of probabilities that is used to generate the random graph.
<li>
<strong>Number of iterations</strong>: The number of times the matrix is “Kronecker multiplied” by itself. The number of nodes in the generated graph is <span class="math">\(2^n,\)</span> where <span class="math">\(n\)</span> is the number of iterations.
</li>
      </ul>
    </div>
  </div>
  <div class="span6">
    <div id="controller" style="font-size:smaller">
        <div class="row-fluid"> <div>
<strong>Number of iterations:</strong>
<div id="iterationsvalue" style="display:inline">

</div>
</div></div>
        <div class="row-fluid"> <div id="iterationsslider"></div> </div>
        <div class="row-fluid" style="margin-top:5px; margin-bottom:2px"> <div>
<strong>Probabilities in 2x2 initiator matrix:</strong>
</div> </div>
        <div class="row-fluid">
           <div class="span4" style="padding-top:12px"> <div id="a1slider"></div> </div> <div class="span2 matrixval"> <div id="a1value"></div> </div>
           <div style="margin:0" class="span2 matrixval"> <div id="a2value"></div> </div> <div class="span4" style="padding-top:12px"> <div id="a2slider"></div> </div>
        </div>
        <div class="row-fluid">
           <div class="span4" style="padding-top:12px"> <div id="b1slider"></div> </div> <div class="span2 matrixval"> <div id="b1value"></div> </div>
           <div style="margin:0" class="span2 matrixval"> <div id="b2value"></div> </div> <div class="span4" style="padding-top:12px"> <div id="b2slider"></div> </div>
        </div>
        <div class="row-fluid">
          <div style="text-align:center; margin-top:10px" class="span12"> <div id="regenerate"></div> </div>
        </div>
    </div>
  </div>
</div>

<div class="row-fluid">
  <div class="span6">
    <div id="graph"></div>
  </div>
  <div class="span6">
    <div id="matrix"></div>
  </div>
</div>

<h1 id="introduction-to-natural-graphs">Introduction to natural graphs</h1>
<h2 id="background-and-motivation">Background and motivation</h2>
<p>At Lab41, <a href="http://lab41.github.io/blog/2013/06/12/i-see-graphs/">we see graphs everywhere</a>. Much of our work revolves around analyzing and generating natural graphs that have structural properties similar to those found in real-world settings. Such graphs could represent an arrangment of computers in a network, animals in a food chain, or neurons in your brain. Unlike randomly-generated graphs, natural graphs have <em>meaning</em>. For example, characteristics of a system modeled by a graph can be deduced by calculating mathematical metrics such as its nodes’ <em>degree</em> (the number of edges connected to a node in a graph) or the number of triangles formed by its edges.</p>
<p>Working with natural graphs involves a number of challenges:</p>
<ul>
<li><p><strong>Obtaining natural graphs is hard.</strong> One must painstakingly collect a large dataset of real-world observations and connections, find a suitable way to interpret it as a graph, and then actually convert it into a graph - a process that can be tedious and time-consuming.</p></li>
<li><p><strong>Datasets for natural graphs are scarce.</strong> There are only a small number of existing datasets representing natural graphs. In fact, at the recent <a href="http://graphlab.org/graphlab-workshop-2013/">GraphLab workshop</a>, one speaker noted that he was getting tired of every presenter using the same dataset (articles and links between them on <a href="http://www.wikipedia.org/">Wikipedia</a>) for their analyses!</p></li>
<li><p><strong>Synthetic graphs miss the mark.</strong> Graphs randomly generated according to standard models (as my colleague Charlie did in <a href="blog/2013/05/02/zero-to-large/">his previous post</a>, and others have done using the <a href="http://en.wikipedia.org/wiki/Erdos-Renyi_model">Erdos-Renyi graph model</a>) tend to look <em>unnatural</em>, no matter what parameters we use. We can’t just create natural graphs by taking a random number generator and going crazy. Instead, we need to find out what properties make a graph “natural,” and then find a way to effectively and efficiently generate graphs with those properties.</p></li>
</ul>
<h2 id="properties-of-natural-graphs">Properties of natural graphs</h2>
<p>So, what makes a graph “natural”? While there is no hard-and-fast definition, nearly all natural graphs exhibit two simple properties:</p>
<ul>
<li><p><strong>Power-law degree distributions.</strong> A very small number of nodes have a very large number of connections (high degree), while a large number of nodes have a very small number of connections (low degree). Mathematically speaking, this means the degree of any vertex in the graph can be interpreted as a random variable that follows a <a href="http://en.wikipedia.org/wiki/Power-law_distribution">power-law probability distribution.</a></p></li>
<li><p><strong>Self-similarity.</strong> In natural graphs, the large-scale connections between parts of the graph reflect the small-scale connections within these different parts. Such a property also appears within fractals, such as the <a href="http://en.wikipedia.org/wiki/Mandelbrot_set">Mandelbrot</a> or <a href="http://en.wikipedia.org/wiki/Julia_set">Julia</a> sets.</p></li>
</ul>
<p>An accurate mechanism for natural graph generation must preserve these properties. As it turns out, the <a href="http://arxiv.org/abs/0812.4905"><strong>stochastic Kronecker graph model</strong></a> does this. It has a few other advantages as well:</p>
<ul>
<li><p><strong>Parallelism.</strong> The model allows large graphs to be generated at scale via parallel computation.</p></li>
<li><p><strong>Structural summarization.</strong> The model provides a very succinct, yet accurate, way to “summarize” the structural properties of natural graphs. Two Kronecker graphs generated with the same parameters will produce graphs with matching values for common structural metrics, such as degree distribution, diameter, hop number, scree value, and network value.</p></li>
</ul>
<p>The remainder of this blog post will describe the basic Kronecker generation algorithm and how it can be modified to efficiently generate very large graphs via parallel computation, on top of MapReduce and Hadoop.</p>
<h1 id="mathematical-formulation">Mathematical formulation</h1>
<p>The core of the Kronecker generation model is a simple matrix operation called the <em>Kronecker product</em>, an operation on two matrices that “nests” many copies of the second within the first. Since graphs can be represented by adjacency matrices (<a href="http://lab41.github.io/blog/2013/06/12/i-see-graphs/">Karthik’s post</a>), this operation can be generalized to graphs.</p>
<p>Taking the Kronecker product of a graph with itself thus easily produces a new, self-similar graph, as does taking the more general “Kronecker power” of it. In fact, Kronecker powers will have further self-similarity. For example, below you can see an example of a simple three-node graph, its Kronecker cube, and its Kronecker fourth power, with the self-similarity evident in the adjacency matrix.</p>
<p><span class="caption-wrapper"><img class='caption' src='/images/2013-08-27-stochastic-kronecker-natural-graphs/matrix.jpg' width='' height='' title='Fractal patterns visible in the adjecency matrix of a Kronecker graph. Taken from Leskovec et al. (2008).'><span class="caption-text">Fractal patterns visible in the adjecency matrix of a Kronecker graph. Taken from Leskovec et al. (2008).</span></span></p>
<p>Because the Kronecker power so easily generates self-similar graphs, it’s reasonable to consider that it might be similarly effective at generating <em>random</em> natural graphs. To do this, we simply start with an adjacency matrix, but allow <em>probabilities</em> to occupy the cells of the matrix rather than ones and zeros. This gives us the <em>stochastic</em> Kronecker graph model.</p>
<h1 id="algorithms-for-generating-kronecker-graphs">Algorithms for generating Kronecker graphs</h1>
<h2 id="naive-algorithm">Naive algorithm</h2>
<p>The simplest algorithm for generating Kronecker graphs is to use Kronecker powers to generate a stochastic adjacency matrix, and then step through each cell of the matrix, flipping a coin biased by the probability present in that matrix. In more detail, the algorithm is as follows:</p>
<ol type="1">
<li><p>We start with an <span class="math">\(n\)</span> by <span class="math">\(n\)</span> initiator matrix, <span class="math">\(\theta,\)</span> and the number of iterations <span class="math">\(k\)</span> for which we wish to run the algorithm. We compute the <span class="math">\(k\)</span>-th Kronecker power of the matrix <span class="math">\(\theta,\)</span> giving us a large matrix of probabilities, which we call <span class="math">\(P.\)</span> Each cell in this matrix corresponds to an edge between two nodes in the graph; the formula for the value at the <span class="math">\((u,v)\)</span>th cell of <span class="math">\(P\)</span> is: <span class="math">\[\prod_{i=0}^{k-1} \theta\left[\left\lfloor \frac{u}{n^i}\right\rfloor \bmod{n},
    \left\lfloor \frac{v}{n^i}\right\rfloor \bmod{n} \right].\]</span> (For convenience, we have assumed the matrix is zero-indexed, as is common in computer science.)</p></li>
<li><p>To generate the actual graph, we 1) step through each cell in the matrix, 2) take the probability in the cell, 3) flip a coin biased by that probability, and if the coin “comes up heads,” we 4) place the corresponding edge in the graph.</p></li>
</ol>
<p>If the initiator matrix is an <span class="math">\(n\times n\)</span> square matrix, and we perform <span class="math">\(k\)</span> iterations of the Kronecker power operation, the generated matrix will have dimension <span class="math">\(N=n^k.\)</span> We will need to take a product of <span class="math">\(k\)</span> values to obtain each cell of the final matrix, and there will be <span class="math">\(N^2\)</span> cells, so the runtime of this algorithm will be <span class="math">\(O(kN^2).\)</span></p>
<p>This means that if we want to generate a graph with approximately one billion nodes (a reasonable size for a large natural graph) from an initiator matrix of size 2, our runtime expression tells us we should expect to perform approximately <span class="math">\({(30)(10^9)^2 = 3.0\times 10^{19}}\)</span> operations. That’s 30 <em>quintillion</em> operations. This leads us to wonder whether we could do this with fewer operations. Spoiler alert: it’s possible.</p>
<h2 id="fast-algorithm">Fast algorithm</h2>
<p>If we switch from a node-oriented approach to an edge-oriented approach, there does exist a faster algorithm for generating a Kronecker graph. Most natural graphs are sparse - <span class="math">\(E = O(N).\)</span> Thus, if we can find a way to place each <em>edge</em>, one at a time, in the graph, rather than figuring out if a pair of nodes has an edge between them, we can vastly reduce the on-average running time. To do this, we need to figure out how many edges are in the graph, and we need to figure out which nodes are associated with each edge.</p>
<p>It turns out that the expected number of edges in a stochastically generated Kronecker graph is encoded within the initiator matrix itself - it’s given by: <span class="math">\[E = \left(\sum_{i,j} \theta[i,j]\right)^k.\]</span> In general, this works out to being on the order of the number of nodes.</p>
<p>Next, we need to find a procedure that starts from nothing, and in <span class="math">\(k\)</span> iterations picks a new edge in the graph to add. Thankfully, this operation is already staring us in the face - in the formula presented in the previous section. Here it is again: <span class="math">\[\prod_{i=0}^{k-1} \theta\left[\left\lfloor \frac{u}{n^i}\right\rfloor \bmod{n},
\left\lfloor \frac{v}{n^i}\right\rfloor \bmod{n} \right].\]</span> This formula can be understood in a different way - as a “recursive descent” into the adjacency matrix of the graph, picking smaller and smaller blocks of the matrix until we have finally narrowed our choice to a single cell, which we then “color in” to represent that an edge should be placed there.</p>
<p>Thus, to generate a stochastic Kronecker graph, all we need to do is set up a loop which runs <span class="math">\(E\)</span> times, generating a new edge in the graph on each pass-through. (If we generate the same edge twice, we ignore it and repeat the pass-through as if nothing happened.) This runs in <span class="math">\(O(kE)\)</span> time, which means that for sparse, real-world graphs, it runs in <span class="math">\(O(kN)\)</span>.</p>
<h2 id="parallel-algorithm">Parallel algorithm</h2>
<p>This algorithm allows us to generate every edge in the graph independently of every other edge, allowing us to parallelize the graph’s generation. This means we can leverage the power of Hadoop to generate very large graphs.</p>
<p>The only twist is that this method allows for the creation of duplicate edges, and most of the graphs we’re interested in don’t contain such duplicates. Thus, we need to figure out how to identify and eliminate them. This is hard when generating the graph across multiple machines, because it’s very likely the duplicate edges will be generated on separate machines. Fortunately, with a bit of cleverness, we can leverage the nature of MapReduce to do our duplicate checking. Instead of one MapReduce job, we’ll have three - one to generate edges and eliminate duplicates, one to generate vertices, and one to combine the two together to form a single graph. This gives us the workflow below.</p>
<p><span class="caption-wrapper"><img class='caption' src='/images/2013-08-27-stochastic-kronecker-natural-graphs/workflow.png' width='' height='' title='The workflow for Kronecker graph generation. Datatypes appear above the line, sample data below. For convenience, FaunusVertex objects have been represented in JSON and NodeTuple objects by pairs of values between angle brackets.'><span class="caption-text">The workflow for Kronecker graph generation. Datatypes appear above the line, sample data below. For convenience, FaunusVertex objects have been represented in JSON and NodeTuple objects by pairs of values between angle brackets.</span></span></p>
<p>The pipeline consists of three stages:</p>
<ol type="1">
<li><p>The first stage of our pipeline is vertex generation. This is the simplest stage - it is a map-only job, utilizing a custom input format representing a range of vertices to be generated. We use as the key a unique <code>Long</code> identifying the vertex, and a <code>FaunusVertex</code> object as the value, giving us a (<code>Long,FaunusVertex</code>) output sequence file.</p></li>
<li><p>The second stage of our pipeline is edge generation. As with vertex generation, it uses a custom input format representing a quota of edges to place into the graph. For each edge in this quota, we run the fast stochastic Kronecker placement algorithm, yielding a tuple of vertex IDs that represents a directed edge in the graph. This tuple is stored as a custom intermediate key type (called a <code>NodeTuple</code>), with the value as a <code>NullWritable</code>; this allows the shuffling and sorting logic of MapReduce to place identical tuples together, and consequently allows us to easily eliminate duplicate copies of the directed edges before the reduce step. Finally, in our reduce step, we emit a <code>Long,FaunusVertex</code> tuple. The <code>FaunusVertex</code> represents the edge’s source vertex and contains a <code>FaunusEdge</code> indicating its destination vertex. The <code>Long</code> key is the source vertex’s ID.</p></li>
<li><p>The third and final stage of our pipeline reads in the vertex objects generated by both the edge and vertex creators and combines them, creating a final list of <code>FaunusVertexes</code> that represents the graph.</p></li>
</ol>
<p>A few details on the pipeline:</p>
<ul>
<li><p><strong>Faunus.</strong> This pipeline uses the same data types as the <a href="http://faunus.thinkaurelius.com">Faunus</a> engine for graph analytics. Faunus provides objects representing edges (<code>FaunusEdge</code>s) and vertices (<code>FaunusVertex</code>es) that can be serialized and utilized by MapReduce jobs but can also serve as a final representation of a graph. Conveniently, <code>FaunusVertex</code>es can store the edges coming off them as well, so we do not need to store edges separately from vertices in the final graph - we need only store the list of vertices with edges added to them.</p></li>
<li><p><strong><code>SequenceFiles</code>.</strong> This pipeline produces <code>SequenceFiles</code> (a native MapReduce serialization format) consisting of <code>FaunusVertex</code>es to serve as intermediate representations of the graph as we construct it.</p></li>
<li><p><strong>Annotations.</strong> In the final stage, we annotate the vertices with several property values (a mixture of floating-points and strings) in order to mimic the data we are interested in.</p></li>
</ul>
<h1 id="further-reading">Further reading</h1>
<p>We have written a version of this blog post up as an informal paper that can be viewed <a href="/assets/post.pdf">here.</a> It contains a more in-depth explanation of the mathematics behind Kronecker graphs.</p>
<h1 id="references">References</h1>
<ul>
<li>Leskovec, Jure, Deepayan Chakrabarti, Jon Kleinberg, Christos Faloutsos, and Zoubin Ghahramani. Kronecker graphs: an approach to modeling networks. <em>ArXiv</em>, <a href="http://arxiv.org/abs/0812.4905">arXiv:0812.4905v2</a></li>
</ul></div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h3 class="entry-title"><a href="/blog/2013/06/12/i-see-graphs/">I See Graphs</a></h3>
    
    
    
    
      <p class="meta">
        








  


<time datetime="2013-06-12T15:17:00+00:00" pubdate data-updated="true">Jun 12<span>th</span>, 2013</time>
        
        
  

<span class="byline author vcard"> - <span class="fn">Karthik Ramachandran</span></span>

        
      </p>
    
  </header>


  <div class="entry-content"><p>At Lab41 we are obsessed with <a href="http://en.wikipedia.org/wiki/Graph_(mathematics)">graphs</a>. We see graphs everywhere we look, in everything we think about. One of our goals is to better understand and advance techniques for manipulating, storing, and analyzing graphs. In this post, we try and do three things: (1) explain what a graph is, (2) show that it’s an important concept, and (3) discuss a way of working with graphs. More specifically, we talk about how to work with graphs as matrices.</p>
<h3 id="why-are-graphs-important">Why are graphs important?</h3>
<p><img class="right" src="/images/2013-06-12-i-see-graphs/directed_graph.png"> A graph is a mathematical construct that describes things that are linked together. Graphs model networks-systems of “things” connected together in some way. For example, the Internet is a physical network of computers connected together by data connections; the Web is a logical network of web pages connected by hyperlinks; and human societies are networks of people connected together by various social relationships. In the language of mathematics, we say each of the “things” in a network is a node and they are connected by “edges.”</p>
<p>It turns out that you can think of much of the world, both physical and virtual, as a graph. As a mathematical construct, graphs have been around since <a
href="http://en.wikipedia.org/wiki/Seven_Bridges_of_K%C3%B6nigsberg">Leonhard Euler tried to figure out the best way to get around Konigsberg in 1735</a>. Since then, graph theory has been embraced by a wide array of disciplines including sociology, economics, physics, computer science, biology, and statistics. An excellent resource for understanding how graphs map onto real world systems is the <a href="http://www.santafe.edu/media/workingpapers/90-004.pdf">“Rosetta Stone for Connectionism,”</a> which maps various real world systems onto graph concepts. Graphs really are everywhere.</p>
<p>While graphs are prevalent in many fields, the tools for working with graphs, especially large graphs, are still in their infancy. As graph technologies mature it should become easier to model many different problems, and easier to implement solutions. However, we are still figuring out the best ways to store, query, and compute on graphs. Right now, people use different data structures and technologies for different types of graphs and different use cases. Eventually, we need to figure out how to hide that complexity and let people treat graph data as graphs without thinking about what the right tools are for manipulating that data. Marko Rodriguez, a leading graph technologist, has a great summary of several different types of graphs and graph technologies in his <a href="http://markorodriguez.com/2013/01/09/on-graph-computing/">recent blog post</a>. Lab41 is actively using and working with many of the technologies that Marko describes, including the graph database Titan, which we load tested as noted in <a href="https://github.com/tinkerpop/blueprints/wiki/Property-Graph-Model">our previous blog entry</a>.</p>
<p><img class="center" src="/images/2013-06-12-i-see-graphs/java_graph.png" title="Graph of Java standard class library generated with Gephi 0.8.2" ></p>
<h3 id="graphs-as-matrices">Graphs as Matrices</h3>
<p>The earliest tools for working with graphs were tools for manipulating matrices. In mathematics, graphs are frequently expressed as an <a href="http://en.wikipedia.org/wiki/Adjacency_matrix">adjacency matrix</a>. In an adjacency matrix each row/column represents a node, and each entry in the matrix represents the presence of an edge between two nodes. The cool thing about the matrix form of a graph is that once you think of a graph as a matrix, you can apply concepts and methods from linear algebra to your graph analysis. Many common graph metrics and algorithms can easily be expressed in terms of standard matrix operations.</p>
<p><img class="center" src="/images/2013-06-12-i-see-graphs/matrix.png" title="A graph represented as an ajacency matrix" ></p>
<p>The cool thing about the matrix form of a graph is that once you think of a graph as a matrix, you can apply concepts and methods from linear algebra to your graph analysis. Many common graph metrics and algorithms can easily be expressed in terms of standard matrix operations.</p>
<p>While an adjacency matrix is a mathematical abstraction, it’s also a data structure. In this post we are talking primarily about a matrix as a contiguous block of memory. In most programing languages this is an array of arrays:</p>
<div class="bogus-wrapper">
<notextile>
<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>//Java
</span><span class='line'>int[][] matrix = {{1,2,3}, {1,2,3}}</span></code></pre></td></tr></table></div></figure>
</notextile>
</div>
<p>From an engineering perspective, there are a number of advantages to storing a graph as a matrix, if the matrix representation of the graph fits in memory:</p>
<ul>
<li>A number of common operations can be performed on matrices quite quickly in comparison to how long they would take on other data structures. (Table 1)
<div class="table-lab41">
<pre><code>&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt; Operation &lt;/td&gt;
    &lt;td&gt; Adjacency Matrix &lt;/td&gt;
    &lt;td&gt; Adjacency List &lt;/td&gt;
    &lt;td&gt; Adjacency Tree &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt; Insert &lt;/td&gt;
    &lt;td&gt; O(1) &lt;/td&gt;
    &lt;td&gt; O(1) &lt;/td&gt;
    &lt;td&gt; O(log(m/n))&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Delete&lt;/td&gt;
    &lt;td&gt;O(1)&lt;/td&gt;
    &lt;td&gt;O(m/n)&lt;/td&gt;
    &lt;td&gt;O(log(m/n))&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Find&lt;/td&gt;
    &lt;td&gt;O(1)&lt;/td&gt;
    &lt;td&gt;O(m/n)&lt;/td&gt;
    &lt;td&gt;O(log(m/n))&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Enumerate&lt;/td&gt;
    &lt;td&gt;O(n)&lt;/td&gt;
    &lt;td&gt;O(m/n)&lt;/td&gt;
    &lt;td&gt;O(m/n)&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;</code></pre>
</div></li>
<li>Nearly all programming languages have highly optimized libraries for storing and working with matrices. For example: Python- <a href="http://www.numpy.org/">NumPy</a>; Java-<a href="http://math.nist.gov/javanumerics/jama/">JAMA</a>, <a href="http://acs.lbl.gov/software/colt/">Colt</a>,<a href="https://code.google.com/p/java-matrix-benchmark/">etc..</a>; C++: <a href="http://arma.sourceforge.net/">Armadillo</a>, <a href="http://eigen.tuxfamily.org/index.php?title=Main_Page">Eigen</a>, etc.</li>
</ul>
However, matrices are a relatively limited representation of a graph. There are a number of operations that they perform very poorly, and they can be very memory inefficient:
<ul>
<li>
Adjacency matrices only allow you to capture the structure of the graph. They don’t give you a chance to associate information with each node – in other words, you can’t represent <a href="https://github.com/tinkerpop/blueprints/wiki/Property-Graph-Model">property graphs</a> with matrices. For example, if you were modeling the world wide web you might want to store the url, title, and text of each web page in the network, and you can’t do that with an adjacency matrix. Now, if you’re persnickety, you might argue that it’s possible to store edge properties in an adjacency matrix if you think of each entry in the matrix as something other than a numeric value.
</li>

<li> 
You can’t model heterogeneous graphs consisting of different types of entities using an adjacency matrix. For example, if you are trying to implement collaborative filtering, you may want to model a network of users to products. Again, if you are persnickety, you might propose various ways of simulating heterogeneous graphs using a single matrix. However, all of those methods will require you to use information not actually stored in the matrix to differentiate nodes of one type from nodes of another.
</li>

<li> 
Adjacency matrices are really slow at some critical matrix operations, such as running through the neighbors of a particular node on a sparse matrix (O(n)– where n is the number of nodes in the graph).
</li>

<li> <p>
Perhaps worst of all, adjacency matrices are very memory inefficient taking O(n^2) memory. An adjacency matrix has an entry for each possible edge, which means each possible edge is using memory even if it does not exist. This is primarily a problem when working with sparse networks – networks where many of the edges in the network don’t exist. Unfortunately, most real world networks are sparse. For example, if you consider the graph of all people on earth, it is a sparse network because each person knows only a relatively small number of other people. Most of the possible relationships that could exist between people don’t exist. In some ways that is both an engineering problem and an existential problem.
</p>
<p>
To put the memory inefficiency of adjacency matrices into perspective, if each edge in a matrix is stored as a 32 bit integer then the memory requirement for a graph can be calculated by following equation:
</p>
<span class="math">\[\text{memory in gb} = \frac{(\text{number of nodes})^2 * 8}{(1024^3)}\]</span>
<p>
Thus a graph of 50,000 nodes would take about 10GB of memory, which means you can’t store and manipulate large graphs like the graph of the Web, which is estimated to have 4.7 billion nodes, on most desktop computers.
</p>

</li>

<p>While technologies for dealing with small matrices – matrices that can fit in memory – are well developed, technologies for dealing with large matrices in a distributed manner are just emerging. One approach to dealing with extremely large matrices is to use some type of super computer, which has a lot of memory. Another approach is to swap portions of the matrix into and out of memory; there are algorithms that can do this relatively efficiently based on the unique properties of a matrix. A new, and extremely interesting, approach is to distribute a matrix computation across the memory of multiple computers. I think the <a href="http://www.cs.cmu.edu/~pegasus/">Pegasus project</a> is a particularly interesting example of the distributed matrix computation approach.</p>
<h3 id="next-steps">Next Steps</h3>
<p>If you’re interested in learning more about networks and adjacency matrices, I would highly recommend taking a look at M.E.J. Newman’s <a href="http://www.amazon.com/Networks-An-Introduction-Mark-Newman/dp/0199206651/ref=sr_1_1_bnp_1_har?ie=UTF8&amp;qid=1370024687&amp;sr=8-1&amp;keywords=Newman+Networks">Networks</a>. He has an excellent discussion of the adjacency matrix as a mathematical concept in Chapter 6, and discussion of an adjacency matrix as a data structure in Chapter 9.</p>
<p>Also, keep an eye on this blog. I plan to address other data structures for storing graph data, and when they may (or may not be) appropriate in a future post.</p></div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/7/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/5/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  This project is maintained by the <a href="https://github.com/LAB41">Lab41</a> Team to serve as a platform of discussion on technology topics relevant to Lab41 Challenges. More information about Lab41 can be found at <a href="http://www.lab41.org">www.lab41.org</a>.
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2015/07/28/triplewide-trailer-looking-to-rig-ipython/">Triplewide Trailer, Part 1</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/04/13/ipython-on-spark-on-docker/">Using Docker to Build an IPython-driven Spark Deployment</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/03/13/skyline/">Introducing&#8230;SKYLINE</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/02/04/circulo-community-detection/">Circulo: A Community Detection Evaluation Framework</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/12/18/rolx-discovering-individuals-roles-in-a-social-network/">Beyond Community Detection - RolX</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/lab41">@lab41</a> on GitHub
  
  <script type="text/javascript">
   (function($) {
    $(document).on('ready', function() {
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'lab41',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
   })(jQuery);
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>

<section>
  <h1>Blog Authors</h1>
  <ul id="blog_authors">
    

    

    

    

    

    

    

    

    

    

    

    

    

    
    <li><a href="https://github.com/kylef-lab41" target="_blank">Kyle Foster</a></li>
    <li><a href="https://github.com/aganeshLab41" target="_blank">Abhinav Ganesh</a></li>
    <li><a href="https://github.com/ks-lab41" target="_blank">Kabir Soorya</a></li>
    <li><a href="https://github.com/Lab41PaulM" target="_blank">Paul Mazzuca</a></li>
    <li><a href="https://github.com/ymt123" target="_blank">Yonas Tesfaye</a></li>
    <li><a href="https://github.com/nadesai" target="_blank">Nikhil Desai</a></li>
    <li><a href="https://github.com/cglewis" target="_blank">Charlie Lewis</a></li>
    <li><a href="https://github.com/ostrowr" target="_blank">Robbie Ostrow</a></li>
    <li><a href="https://github.com/karkumar" target="_blank">Karthik Ramachandran</a></li>
  </ul>
</section>




  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2015 - Lab41 -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a>. Design by <a href="http://octopressthemes.com">Octopress Themes</a>.</a></span>
  <br>
  <span>
    Background image: <a href="https://www.flickr.com/photos/vkurland/8219699128">"Stanford Dish hiking trail"</a> by <a href="https://www.flickr.com/photos/vkurland/">Vadim Kurland</a>, used under <a href="https://creativecommons.org/licenses/by/2.0">CC BY 2.0</a> / Desaturated from original
  </span>
</p>

</footer>
  







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'https://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
